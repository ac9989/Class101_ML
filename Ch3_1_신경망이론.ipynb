{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch3_1_신경망이론.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0itqtHuZljA"
      },
      "source": [
        "- 순방향전파\n",
        "\n",
        "입력신호------->은닉신호------->출력신호\n",
        "\n",
        ".....(X).....(W1)......(h)......(W2).....(Y^)\n",
        "\n",
        "\n",
        "=> $h = X W_{1}, Ŷ = hW_{2}$, 즉 이론적으로 $Ŷ=XW_{1}W_{2} =XW_{3}$\n",
        "\n",
        "하지만 이렇게되면 중간과정을 생략하게 되므로 비선형적 구조로 만들기위해\n",
        "\n",
        "$h = σ(X W_{1}), Ŷ = σ(hW_{2})$, $Ŷ=σ(σ(XW_{1})W_{2})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHOCrJjuYgar"
      },
      "source": [
        "def forword(X):\n",
        "  X = np.matmul(X,W1)\n",
        "  X = act_func(X)\n",
        "  X = np.matmul(X,W2)\n",
        "  X = act_func(X)\n",
        "  return X   # Y^\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQD0I98LY6nY"
      },
      "source": [
        "def forword(X):\n",
        "  X = Linear1(X)\n",
        "  X = F.act(X)\n",
        "  X = Linear2(X)\n",
        "  X = F.act(X)\n",
        "  return X\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baA-e6AxcwbD"
      },
      "source": [
        "- 역방향전파\n",
        "\n",
        " 신경망추론값($Ŷ$)과 실제 데이터($Y$)값의 차이를 최소화시키기 위함\n",
        "\n",
        "$L=dist(Ŷ,Y)$, 학습량과 L값은 반비례\n",
        "\n",
        "학습순서\n",
        "(경사하강법에서 배운 그 공식을 따름 : $θ⃖θ-α\\nabla f$)\n",
        "\n",
        "1. $W_{2}⃖W_{2}-α\\frac{\\partial L}{\\partial W_{2}}$\n",
        "2. $W_{1}⃖W_{1}-α\\frac{\\partial L}{\\partial W_{1}}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "8cp1dtGKfnhF",
        "outputId": "7438c501-c1ac-4349-ec2f-a3707d8d2816"
      },
      "source": [
        "loss = L(y_,y) #오차함수 정의\n",
        "loss.backward() # 역전파 시행\n",
        "optim.step() # 최적화 시행(SGD)\n",
        "\n",
        "#https://cs231n.github.io/optimization-2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8531b5d63481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'L' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP9oAg3ZDWri"
      },
      "source": [
        "(3) -> (5) -> (2) 로 가정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jvn95UOf1xW"
      },
      "source": [
        "#PyTorch 필요 라이브러리 호출\n",
        "import torch # pip install pytorch : 실무에 들어갔는데 안될 때\n",
        "import torch.nn as nn #뉴런 네트워크\n",
        "import torch.nn.functional as F # 토치 속 함수\n",
        "import torch.optim as optim # 토치를 통한 최적화"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWK4P3aHEdFd"
      },
      "source": [
        "#Neural network 모델 생성\n",
        "#입력 -> 은닉 (3,5)\n",
        "#은닉 -> 출력 (5,2)\n",
        "class fir_model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(fir_model,self).__init__()\n",
        "    #가중치 행렬 1\n",
        "    self.lin1 = nn.Linear(3,5)\n",
        "    #가중치 행렬 2\n",
        "    self.lin2 = nn.Linear(5,2)\n",
        "  #formard propagation\n",
        "  def forward(self,x):\n",
        "    x = self.lin1(x) # 3,5행렬 통과\n",
        "    x = F.relu(x) # relu 활성화 함수 통과\n",
        "    x = self.lin2(x)\n",
        "    x = F.sigmoid(x)\n",
        "    return x\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeVMgHeLGRix"
      },
      "source": [
        "# Neural network 모델 정의 및 최적화 툴(optimizer)\n",
        "model = fir_model()\n",
        "opt = optim.SGD(model.parameters(),lr=0.01) # Adam, PMSprop : SGD보다 조금 더 발전된 형태\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aI_m7V0mHLqS",
        "outputId": "ab366766-9d90-49df-9e1c-af5f52bbb329"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fir_model(\n",
            "  (lin1): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (lin2): Linear(in_features=5, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7beQFBgoahC3",
        "outputId": "a733c7ef-eabb-446f-cde5-e2e27f2d6f95"
      },
      "source": [
        "import numpy as np\n",
        "#backward propagation\n",
        "#이 셀은 실행되지않음(x,y가 정의되지않았기 때문)\n",
        "criterion = nn.MSELoss() #criterion변수는 (MSELoss == (y^ - y)**2)\n",
        "\n",
        "x = torch.Tensor(np.random.normal(size=(3))) #입력 데이터(3차원)\n",
        "y = torch.Tensor(np.random.normal(size=(2))) #출력 데이터(2차원)\n",
        "\n",
        "opt.zero_grad() #optimizer 안 모든 미분값(gradient)을 0으로 초기화 \n",
        "               #: 초기화하지않으면 계속해서 값이 쌓이게되므로 계속해서 값을 비워둬야함\n",
        "y_infer = model(x)  #forward propagation\n",
        "loss = criterion(y_infer,y) # 즉 거리인 셈, 직접 만들수도 있음\n",
        "loss.backward()\n",
        "opt.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1pQoGhYrM_V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}